{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from model import LSTMModel\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_stat_label(folder_path, to_exclude: list[str] = [], to_include: list[str] = []):\n",
    "    all_dfs = []\n",
    "    file_paths = os.listdir(folder_path)\n",
    "    if to_exclude:\n",
    "        file_paths = [file for file in file_paths if file not in to_exclude]\n",
    "    if to_include:\n",
    "        file_paths = [file for file in file_paths if file in to_include]\n",
    "    for filename in tqdm(file_paths):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_dfs.append(df)\n",
    "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    label_stats = merged_df['Label'].value_counts()\n",
    "    return merged_df, label_stats\n",
    "\n",
    "\n",
    "def filter_by_min_count(df, label_column, min_count):\n",
    "    label_counts = df[label_column].value_counts()\n",
    "    valid_labels = label_counts[label_counts >= min_count].index\n",
    "    return df[df[label_column].isin(valid_labels)]\n",
    "\n",
    "def process_input_and_generate_result(scaled_X, X_matrix, column_matrix):\n",
    "    \"\"\"\n",
    "    Hàm nhận vào ma trận X và trả về kết quả tương ứng.\n",
    "\n",
    "    :param X: Ma trận X chứa các chỉ số (index) để truy cập vào X_matrix và column_matrix\n",
    "    :param scaled_X: Ma trận scaled_X chứa các chỉ số để truy cập vào các giá trị trong X_matrix\n",
    "    :param X_matrix: Ma trận dữ liệu dùng để truy xuất theo các chỉ số từ scaled_X\n",
    "    :param column_matrix: Ma trận cột dùng để kết hợp với các giá trị từ X_matrix\n",
    "    :return: Ma trận kết quả đã được điền dữ liệu từ X_matrix và column_matrix\n",
    "    \"\"\"\n",
    "\n",
    "    result = np.zeros((scaled_X.shape[0], scaled_X.shape[1],\n",
    "                       X_matrix.shape[1] + column_matrix.shape[1]))\n",
    "\n",
    "    for i in range(scaled_X.shape[0]):\n",
    "        for j in range(scaled_X.shape[1]):\n",
    "            x_value = X_matrix[scaled_X[i, j]]\n",
    "            column_value = column_matrix[j]\n",
    "            result[i, j] = np.concatenate((x_value, column_value))\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_input_and_generate_result_tensor(scaled_X, X_matrix, column_matrix):\n",
    "\n",
    "    result = torch.zeros((scaled_X.shape[0], scaled_X.shape[1],\n",
    "                         # (195720, 76, 128)\n",
    "                          X_matrix.shape[1] + column_matrix.shape[1]))\n",
    "\n",
    "    for i in range(scaled_X.shape[0]):\n",
    "        for j in range(scaled_X.shape[1]):\n",
    "            x_value = X_matrix[scaled_X[i, j]]\n",
    "            column_value = column_matrix[j]\n",
    "            result[i, j] = torch.concatenate((x_value, column_value))\n",
    "\n",
    "    return result\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function to process data with process_input_and_generate_result.\n",
    "\n",
    "    :param batch: A batch of data (inputs, targets)\n",
    "    :return: Processed batch (inputs, targets)\n",
    "    \"\"\"\n",
    "    inputs, targets = zip(*batch)  # Tách dữ liệu và nhãn\n",
    "\n",
    "    # Chuyển danh sách inputs thành một tensor 3D, có shape: (batch_size, seq_len, input_size)\n",
    "    inputs = torch.stack(inputs, dim=0)\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    # Giả sử bạn đã có sẵn scaled_X, X_matrix, và column_matrix\n",
    "    # Chuyển đổi dữ liệu sử dụng hàm process_input_and_generate_result\n",
    "    processed_inputs = process_input_and_generate_result(inputs.numpy(), X_matrix, column_matrix)\n",
    "\n",
    "    # Chuyển processed_inputs về dạng tensor\n",
    "    processed_inputs = torch.tensor(processed_inputs, dtype=torch.float32)\n",
    "\n",
    "    return processed_inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Datasets/TabularIoTAttacks-2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:30<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data's shape: int64\n"
     ]
    }
   ],
   "source": [
    "merged_df, label_stats = merge_and_stat_label(folder_path)\n",
    "min_count = 32620\n",
    "filtered_df = filter_by_min_count(merged_df, 'Attack Name', min_count)\n",
    "\n",
    "y = filtered_df['Attack Name']\n",
    "X = filtered_df.select_dtypes(include=['int64', 'float64'])\n",
    "X = X.drop(columns=['Label', 'Src Port', 'Dst Port', 'Protocol'], axis=1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 50000))\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# X_matrix = np.random.rand(50000+1, 64)  \n",
    "# column_matrix = np.random.rand(76, 64)\n",
    "scaled_X = scaled_X.astype(int)\n",
    "\n",
    "print(\"Data's shape:\", scaled_X.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(scaled_X, dtype=torch.long)  \n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tensor, y_tensor, \n",
    "                                                    test_size=0.4, random_state=42, stratify=y_tensor)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, \n",
    "                                                test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "hidden_size = 64  \n",
    "num_layers = 3\n",
    "output_size = len(np.unique(y_encoded))\n",
    "bidirectional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomEmbedding(nn.Module):\n",
    "    def __init__(self, X_matrix: torch.Tensor, column_matrix: torch.Tensor):\n",
    "        super(CustomEmbedding, self).__init__()\n",
    "        self.X_matrix = nn.Parameter(X_matrix, requires_grad=False)\n",
    "        self.column_matrix = nn.Parameter(column_matrix, requires_grad=False)\n",
    "\n",
    "    def forward(self, indices: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Apply the embedding process for input indices using batch processing.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = indices.shape\n",
    "        feature_dim_X = self.X_matrix.shape[1]\n",
    "        feature_dim_C = self.column_matrix.shape[1]\n",
    "\n",
    "        # Efficient batch operation: get X_matrix and column_matrix embeddings\n",
    "        X_embeddings = self.X_matrix[indices]  # (batch_size, seq_len, feature_dim_X)\n",
    "        \n",
    "        # Expand column_matrix to match batch size and seq_len\n",
    "        column_embeddings = self.column_matrix.unsqueeze(0).expand(batch_size, seq_len, feature_dim_C)\n",
    "        \n",
    "        # Concatenate along the last dimension (features dimension)\n",
    "        result = torch.cat((X_embeddings, column_embeddings), dim=-1)\n",
    "\n",
    "        return result\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, \n",
    "                 n_features, X_embedding_dims, column_embedding_dim,\n",
    "                 X_range: tuple,\n",
    "                 num_layers=2, dropout=0.2, **kwargs):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        X_min, X_max = X_range\n",
    "        X_matrix = torch.rand(X_max + 1, X_embedding_dims)\n",
    "        column_matrix = torch.rand(n_features, column_embedding_dim)\n",
    "        self.embedding = CustomEmbedding(X_matrix, column_matrix)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = 2 if kwargs.get('bidirectional') else 1\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout, **kwargs)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size * self.num_directions, num_classes)\n",
    "\n",
    "    def forward(self, indices):\n",
    "        # Process inputs through the embedding layer\n",
    "        x = self.embedding(indices)\n",
    "\n",
    "        # Initialize hidden states\n",
    "        h0 = torch.zeros(self.num_layers * self.num_directions, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * self.num_directions, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # LSTM output\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]  # Last time-step output\n",
    "\n",
    "        # Pass through fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): CustomEmbedding()\n",
       "  (lstm): LSTM(128, 64, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(input_size, hidden_size, num_classes=output_size,\n",
    "                  num_layers=num_layers, bidirectional=bidirectional,\n",
    "                  n_features=X.shape[1], X_embedding_dims=64,\n",
    "                  column_embedding_dim=64, X_range=(0, 50000))\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\KLTN\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  #\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 512 * 2\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./logs/20241215_175915\\\\min_max_scaler.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "log_dir = f'./logs/{timestamp}'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# np.save(os.path.join(log_dir, 'X_matrix.npy'), X_matrix)\n",
    "# np.save(os.path.join(log_dir, 'column_matrix.npy'), column_matrix)\n",
    "np.save(os.path.join(log_dir, 'scaled_X.npy'), scaled_X)\n",
    "np.save(os.path.join(log_dir, 'y_encoded.npy'), y_encoded)\n",
    "\n",
    "joblib.dump(le, os.path.join(log_dir, 'label_encoder.joblib'))\n",
    "joblib.dump(scaler, os.path.join(log_dir, 'min_max_scaler.joblib'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (embedding): CustomEmbedding()\n",
      "  (lstm): LSTM(128, 64, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/1971 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8341,     9,     0,  ...,     0,     0,     0],\n",
      "        [   76,     6,    21,  ...,     0,     0,     0],\n",
      "        [  121,     0,     7,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [49343,    45,     0,  ...,     0,     0,     0],\n",
      "        [30890,    21,     0,  ...,     0, 15590, 15590],\n",
      "        [  123,     0,     7,  ...,     0,     0,     0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = 0.0\n",
    "num_epochs = 1\n",
    "patience = 5\n",
    "no_improve_epochs = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for inputs, targets in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            print(inputs)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50001, 64]), torch.Size([76, 64]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.X_matrix.shape, model.embedding.column_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 76, 128])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4681, 0.8220, 0.9640, 0.6090, 0.3164, 0.2209, 0.3045, 0.0389, 0.5975,\n",
       "        0.0978, 0.9521, 0.5828, 0.5141, 0.6188, 0.5128, 0.7266, 0.0681, 0.0049,\n",
       "        0.8374, 0.9143, 0.6010, 0.2866, 0.2574, 0.3361, 0.7193, 0.8117, 0.8840,\n",
       "        0.5659, 0.4122, 0.1353, 0.2468, 0.9108, 0.7168, 0.0628, 0.2901, 0.6523,\n",
       "        0.4462, 0.7096, 0.0878, 0.7842, 0.8914, 0.7976, 0.2512, 0.2123, 0.0476,\n",
       "        0.2544, 0.3157, 0.7965, 0.3359, 0.5434, 0.4454, 0.1122, 0.5906, 0.1926,\n",
       "        0.3499, 0.6639, 0.9609, 0.4541, 0.0525, 0.3377, 0.0264, 0.0048, 0.4925,\n",
       "        0.1963, 0.4275, 0.8422, 0.8437, 0.5399, 0.0748, 0.4936, 0.7729, 0.5370,\n",
       "        0.6422, 0.1855, 0.4158, 0.0935, 0.0178, 0.9473, 0.5038, 0.4628, 0.2278,\n",
       "        0.2973, 0.8222, 0.7147, 0.3509, 0.8324, 0.5428, 0.5249, 0.1439, 0.2614,\n",
       "        0.5175, 0.0971, 0.5839, 0.3881, 0.3024, 0.6201, 0.9725, 0.4122, 0.4815,\n",
       "        0.4364, 0.9191, 0.6735, 0.8446, 0.0321, 0.8330, 0.7324, 0.5746, 0.4621,\n",
       "        0.0199, 0.3796, 0.7274, 0.8403, 0.9157, 0.3705, 0.8949, 0.5536, 0.3860,\n",
       "        0.1821, 0.9496, 0.7232, 0.5412, 0.0177, 0.1175, 0.0042, 0.3256, 0.0645,\n",
       "        0.1625, 0.2334], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.cat((model.embedding.X_matrix[inputs[0][0]], model.embedding.column_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp == embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy = 0.0\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "no_improve_epochs = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for inputs, targets in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            print(inputs)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += targets.size(0)\n",
    "            correct_train += (predicted == targets).sum().item()\n",
    "            \n",
    "            pbar.set_postfix(loss=epoch_loss / len(train_loader), accuracy=100 * correct_train / total_train)\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    print(f\"Train Loss: {epoch_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    writer.add_scalar('Loss/train', epoch_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += targets.size(0)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    writer.add_scalar('Loss/val', val_loss / len(val_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        no_improve_epochs = 0\n",
    "        model_save_path = os.path.join(log_dir, 'best_model.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"New best model saved at {model_save_path}\")\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs >= patience:\n",
    "        print(\"Early stopping due to no improvement in validation accuracy.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 14:29:04,934 - INFO - Log directory: ./logs/20241216_142904\n",
      "2024-12-16 14:29:04,934 - INFO - Log directory: ./logs/20241216_142904\n",
      "2024-12-16 14:29:04,934 - INFO - Log directory: ./logs/20241216_142904\n",
      "2024-12-16 14:29:04,934 - INFO - Log directory: ./logs/20241216_142904\n",
      "2024-12-16 14:29:04,934 - INFO - Log directory: ./logs/20241216_142904\n",
      "2024-12-16 14:29:04,938 - INFO - Using device: cuda\n",
      "2024-12-16 14:29:04,938 - INFO - Using device: cuda\n",
      "2024-12-16 14:29:04,938 - INFO - Using device: cuda\n",
      "2024-12-16 14:29:04,938 - INFO - Using device: cuda\n",
      "2024-12-16 14:29:04,938 - INFO - Using device: cuda\n",
      "100%|██████████| 5/5 [00:31<00:00,  6.35s/it]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from model import LSTMModel\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from logger import setup_logger\n",
    "\n",
    "logger = setup_logger(log_file=\"logs/training_lstm.log\")\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "log_dir = f'./logs/{timestamp}'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "logger.info(f\"Log directory: {log_dir}\")    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def merge_and_stat_label(folder_path, to_exclude: list[str] = [], to_include: list[str] = []):\n",
    "    all_dfs = []\n",
    "    file_paths = os.listdir(folder_path)\n",
    "    if to_exclude:\n",
    "        file_paths = [file for file in file_paths if any(att in file for att in to_exclude)]\n",
    "    if to_include:\n",
    "        file_paths = [file for file in file_paths if any(att in file for att in to_include)]\n",
    "    for filename in tqdm(file_paths):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_dfs.append(df)\n",
    "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    label_stats = merged_df['Label'].value_counts()\n",
    "    return merged_df, label_stats\n",
    "\n",
    "\n",
    "def filter_by_min_count(df, label_column, min_count):\n",
    "    label_counts = df[label_column].value_counts()\n",
    "    valid_labels = label_counts[label_counts >= min_count].index\n",
    "    return df[df[label_column].isin(valid_labels)]\n",
    "\n",
    "def scale_df(df, scalers):\n",
    "    scaled_df = df.copy()\n",
    "    for i, col in enumerate(df.columns):\n",
    "        scaled_df[col] = scalers[i].fit_transform(df[col].values.reshape(-1, 1))\n",
    "    return scaled_df\n",
    "\n",
    "folder_path = 'Datasets/TabularIoTAttacks-2024'\n",
    "selected_attacks = ['DoS TCP Flood', 'Recon Port Scan', 'MQTT DDoS Publish Flood', 'MQTT DoS Connect Flood', 'Benign Traffic']\n",
    "\n",
    "merged_df, label_stats = merge_and_stat_label(folder_path, to_include=selected_attacks)\n",
    "min_count = 32620\n",
    "filtered_df = filter_by_min_count(merged_df, 'Attack Name', min_count)\n",
    "\n",
    "y = filtered_df['Attack Name']\n",
    "X = filtered_df.select_dtypes(include=['int64', 'float64'])\n",
    "X = X.drop(columns=['Label', 'Src Port', 'Dst Port', 'Protocol'], axis=1)\n",
    "\n",
    "idx_range = (0, 50000)\n",
    "scalers = [MinMaxScaler(feature_range=idx_range) for _ in range(X.shape[1])]\n",
    "scaled_X = scale_df(X, scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packet</th>\n",
       "      <th>Total Bwd packets</th>\n",
       "      <th>Total Length of Fwd Packet</th>\n",
       "      <th>Total Length of Bwd Packet</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Act Data Pkts</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6144.318333</td>\n",
       "      <td>7.844122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1335.616438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.589041</td>\n",
       "      <td>827.433379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.137747</td>\n",
       "      <td>18750.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6118.187105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6118.187105</td>\n",
       "      <td>6118.187105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25042.545833</td>\n",
       "      <td>26.670013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.480914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48219.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7867.199391</td>\n",
       "      <td>23950.825185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.550988</td>\n",
       "      <td>18750.0</td>\n",
       "      <td>96.683836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.683836</td>\n",
       "      <td>96.683836</td>\n",
       "      <td>6233.452823</td>\n",
       "      <td>127.088758</td>\n",
       "      <td>6276.884065</td>\n",
       "      <td>6114.409370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37544.487083</td>\n",
       "      <td>12.550595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.261375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6643.835616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4429.223744</td>\n",
       "      <td>4736.834100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.844368</td>\n",
       "      <td>18750.0</td>\n",
       "      <td>257.029788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257.029788</td>\n",
       "      <td>257.029788</td>\n",
       "      <td>12436.066992</td>\n",
       "      <td>212.827380</td>\n",
       "      <td>12522.604420</td>\n",
       "      <td>12282.950995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49999.575000</td>\n",
       "      <td>191.396567</td>\n",
       "      <td>879.702475</td>\n",
       "      <td>2.337444</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>684.931507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.567992</td>\n",
       "      <td>112.768725</td>\n",
       "      <td>68.493151</td>\n",
       "      <td>...</td>\n",
       "      <td>188.264826</td>\n",
       "      <td>18750.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49999.391250</td>\n",
       "      <td>191.396567</td>\n",
       "      <td>879.702475</td>\n",
       "      <td>5.863658</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>1575.342466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1506.570888</td>\n",
       "      <td>278.322371</td>\n",
       "      <td>68.493151</td>\n",
       "      <td>...</td>\n",
       "      <td>188.264826</td>\n",
       "      <td>18750.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276997</th>\n",
       "      <td>122.409583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.152053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276998</th>\n",
       "      <td>121.410417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.152053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276999</th>\n",
       "      <td>121.102500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.152053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277000</th>\n",
       "      <td>116.226667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.152053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277001</th>\n",
       "      <td>110.186250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.152053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3277002 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Flow Duration  Total Fwd Packet  Total Bwd packets  \\\n",
       "0          6144.318333          7.844122           0.000000   \n",
       "1         25042.545833         26.670013           0.000000   \n",
       "2         37544.487083         12.550595           0.000000   \n",
       "3         49999.575000        191.396567         879.702475   \n",
       "4         49999.391250        191.396567         879.702475   \n",
       "...                ...               ...                ...   \n",
       "3276997     122.409583          0.000000           7.152053   \n",
       "3276998     121.410417          0.000000           7.152053   \n",
       "3276999     121.102500          0.000000           7.152053   \n",
       "3277000     116.226667          0.000000           7.152053   \n",
       "3277001     110.186250          0.000000           7.152053   \n",
       "\n",
       "         Total Length of Fwd Packet  Total Length of Bwd Packet  \\\n",
       "0                          0.068270                    0.000000   \n",
       "1                          4.480914                    0.000000   \n",
       "2                          1.261375                    0.000000   \n",
       "3                          2.337444                    0.020381   \n",
       "4                          5.863658                    0.020381   \n",
       "...                             ...                         ...   \n",
       "3276997                    0.000000                    0.000000   \n",
       "3276998                    0.000000                    0.000000   \n",
       "3276999                    0.000000                    0.000000   \n",
       "3277000                    0.000000                    0.000000   \n",
       "3277001                    0.000000                    0.000000   \n",
       "\n",
       "         Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                  1335.616438                    0.0              359.589041   \n",
       "1                 48219.178082                    0.0             7867.199391   \n",
       "2                  6643.835616                    0.0             4429.223744   \n",
       "3                   684.931507                    0.0              600.567992   \n",
       "4                  1575.342466                    0.0             1506.570888   \n",
       "...                        ...                    ...                     ...   \n",
       "3276997               0.000000                    0.0                0.000000   \n",
       "3276998               0.000000                    0.0                0.000000   \n",
       "3276999               0.000000                    0.0                0.000000   \n",
       "3277000               0.000000                    0.0                0.000000   \n",
       "3277001               0.000000                    0.0                0.000000   \n",
       "\n",
       "         Fwd Packet Length Std  Bwd Packet Length Max  ...  Fwd Act Data Pkts  \\\n",
       "0                   827.433379               0.000000  ...           3.137747   \n",
       "1                 23950.825185               0.000000  ...          12.550988   \n",
       "2                  4736.834100               0.000000  ...           7.844368   \n",
       "3                   112.768725              68.493151  ...         188.264826   \n",
       "4                   278.322371              68.493151  ...         188.264826   \n",
       "...                        ...                    ...  ...                ...   \n",
       "3276997               0.000000               0.000000  ...           0.000000   \n",
       "3276998               0.000000               0.000000  ...           0.000000   \n",
       "3276999               0.000000               0.000000  ...           0.000000   \n",
       "3277000               0.000000               0.000000  ...           0.000000   \n",
       "3277001               0.000000               0.000000  ...           0.000000   \n",
       "\n",
       "         Fwd Seg Size Min  Active Mean  Active Std  Active Max  Active Min  \\\n",
       "0                 18750.0     0.000000         0.0    0.000000    0.000000   \n",
       "1                 18750.0    96.683836         0.0   96.683836   96.683836   \n",
       "2                 18750.0   257.029788         0.0  257.029788  257.029788   \n",
       "3                 18750.0     0.000000         0.0    0.000000    0.000000   \n",
       "4                 18750.0     0.000000         0.0    0.000000    0.000000   \n",
       "...                   ...          ...         ...         ...         ...   \n",
       "3276997               0.0     0.000000         0.0    0.000000    0.000000   \n",
       "3276998               0.0     0.000000         0.0    0.000000    0.000000   \n",
       "3276999               0.0     0.000000         0.0    0.000000    0.000000   \n",
       "3277000               0.0     0.000000         0.0    0.000000    0.000000   \n",
       "3277001               0.0     0.000000         0.0    0.000000    0.000000   \n",
       "\n",
       "            Idle Mean    Idle Std      Idle Max      Idle Min  \n",
       "0         6118.187105    0.000000   6118.187105   6118.187105  \n",
       "1         6233.452823  127.088758   6276.884065   6114.409370  \n",
       "2        12436.066992  212.827380  12522.604420  12282.950995  \n",
       "3            0.000000    0.000000      0.000000      0.000000  \n",
       "4            0.000000    0.000000      0.000000      0.000000  \n",
       "...               ...         ...           ...           ...  \n",
       "3276997      0.000000    0.000000      0.000000      0.000000  \n",
       "3276998      0.000000    0.000000      0.000000      0.000000  \n",
       "3276999      0.000000    0.000000      0.000000      0.000000  \n",
       "3277000      0.000000    0.000000      0.000000      0.000000  \n",
       "3277001      0.000000    0.000000      0.000000      0.000000  \n",
       "\n",
       "[3277002 rows x 76 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
